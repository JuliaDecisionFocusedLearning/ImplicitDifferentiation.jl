var documenterSearchIndex = {"docs":
[{"location":"examples/0_intro/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"We explain the basics of our package on a simple function that is not amenable to naive automatic differentiation.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"using ForwardDiff\nusing ImplicitDifferentiation\nusing LinearAlgebra\nusing Zygote","category":"page"},{"location":"examples/0_intro/#Why-do-we-bother?","page":"Introduction","title":"Why do we bother?","text":"","category":"section"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"ForwardDiff.jl and Zygote.jl are two prominent packages for automatic differentiation in Julia. While they are very generic, there are simple language constructs that they cannot differentiate through.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"function badsqrt(x::AbstractArray)\n    a = [0.0]\n    a[1] = x[1]\n    return sqrt.(x)\nend;\nnothing #hide","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"This is essentially the componentwise square root function but with an additional twist: a::Vector{Float64} is created internally, and its only element is replaced with the first element of x. We can check that it does what it's supposed to do.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"x = [1.0 2.0; 3.0 4.0]\nbadsqrt(x)","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Of course the Jacobian has an explicit formula.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"J = Diagonal(0.5 ./ vec(sqrt.(x)))","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"However, things start to go wrong when we compute it with autodiff, due to the limitations of ForwardDiff.jl and those of Zygote.jl.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"try\n    ForwardDiff.jacobian(badsqrt, x)\ncatch e\n    e\nend","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"ForwardDiff.jl throws an error because it tries to call badsqrt with an array of dual numbers, and cannot use one of these numbers to fill a (which has element type Float64).","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"try\n    Zygote.jacobian(badsqrt, x)\ncatch e\n    e\nend","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Zygote.jl also throws an error because it cannot handle mutation.","category":"page"},{"location":"examples/0_intro/#Implicit-function","page":"Introduction","title":"Implicit function","text":"","category":"section"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"The first possible use of ImplicitDifferentiation.jl is to overcome the limitations of automatic differentiation packages by defining functions (and computing their derivatives) implicitly. An implicit function is a mapping","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"x in mathbbR^n longmapsto y(x) in mathbbR^m","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"whose output is defined by conditions","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"c(xy(x)) = 0 in mathbbR^m","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"We represent it using a type called ImplicitFunction, which you will see in action shortly.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"First we define a forward mapping corresponding to the function we consider. It returns the actual output y(x) of the function as well as a byproduct z (which can be nothing), and can be thought of as a black box solver. Importantly, this Julia callable doesn't need to be differentiable by automatic differentiation packages but the underlying function still needs to be mathematically differentiable.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"forward(x) = (badsqrt(x), nothing);\nnothing #hide","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Then we define conditions c(x y z) = 0 that the output y(x) is supposed to satisfy. These conditions must be array-valued, with the same size as y, and they can involve the byproduct z. Unlike the forward mapping, the conditions need to be differentiable by automatic differentiation packages with respect to both x and y. Here the conditions are very obvious: the square of the square root should be equal to the original value.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"conditions(x, y, _z) = y .^ 2 .- x","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Finally, we construct a wrapper implicit around the previous objects. By default, forward is assumed to return a single output and conditions is assumed to accept 2 arguments.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"implicit = ImplicitFunction(forward, conditions)","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"What does this wrapper do? When we call it as a function, it just falls back on implicit.forward, so unsurprisingly we get the output y(x) and the byproduct z.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"implicit(x)","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"And when we try to compute its Jacobian, the implicit function theorem is applied in the background to circumvent the lack of differentiability of the forward mapping.","category":"page"},{"location":"examples/0_intro/#Forward-and-reverse-mode-autodiff","page":"Introduction","title":"Forward and reverse mode autodiff","text":"","category":"section"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Now ForwardDiff.jl works seamlessly.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"ForwardDiff.jacobian(first ∘ implicit, x) ≈ J","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"And so does Zygote.jl. Hurray!","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Zygote.jacobian(first ∘ implicit, x)[1] ≈ J","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/3_tricks/#Tricks","page":"Tricks","title":"Tricks","text":"","category":"section"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"We demonstrate several features that may come in handy for some users.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"using ComponentArrays\nusing ForwardDiff\nusing ImplicitDifferentiation\nusing LinearAlgebra\nusing Zygote","category":"page"},{"location":"examples/3_tricks/#ComponentArrays","page":"Tricks","title":"ComponentArrays","text":"","category":"section"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"For when you need derivatives with respect to multiple inputs or outputs.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"function forward_components_aux(a::AbstractVector, b::AbstractVector, m::Number)\n    d = m * sqrt.(a)\n    e = sqrt.(b)\n    return d, e\nend\n\nfunction conditions_components_aux(a, b, m, d, e)\n    c_d = (d ./ m) .^ 2 .- a\n    c_e = (e .^ 2) .- b\n    return c_d, c_e\nend;\nnothing #hide","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"You can use ComponentVector from ComponentArrays.jl as an intermediate storage.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"function forward_components(x::ComponentVector)\n    d, e = forward_components_aux(x.a, x.b, x.m)\n    y = ComponentVector(; d=d, e=e)\n    z = nothing\n    return y, z\nend\n\nfunction conditions_components(x::ComponentVector, y::ComponentVector, _z)\n    c_d, c_e = conditions_components_aux(x.a, x.b, x.m, y.d, y.e)\n    c = ComponentVector(; c_d=c_d, c_e=c_e)\n    return c\nend;\nnothing #hide","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"And build your implicit function like so, switching the operator representation to avoid errors with ComponentArrays.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"implicit_components = ImplicitFunction(\n    forward_components,\n    conditions_components;\n    representation=OperatorRepresentation{:LinearMaps}(),\n);\nnothing #hide","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"Now we're good to go.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"a, b, m = [1.0, 2.0], [3.0, 4.0, 5.0], 6.0\nx = ComponentVector(; a=a, b=b, m=m)\nimplicit_components(x)","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"And it works with both ForwardDiff.jl and Zygote.jl","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"ForwardDiff.jacobian(first ∘ implicit_components, x)","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"Zygote.jacobian(first ∘ implicit_components, x)[1]","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"function full_pipeline(a, b, m)\n    x = ComponentVector(; a=a, b=b, m=m)\n    y, _ = implicit_components(x)\n    return y.d, y.e\nend;\nnothing #hide","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"This page was generated using Literate.jl.","category":"page"},{"location":"api/#API-reference","page":"API reference","title":"API reference","text":"","category":"section"},{"location":"api/#Public","page":"API reference","title":"Public","text":"","category":"section"},{"location":"api/#ImplicitDifferentiation","page":"API reference","title":"ImplicitDifferentiation","text":"ImplicitDifferentiation\n\nA Julia package for automatic differentiation of implicit functions.\n\nIts main export is the type ImplicitFunction.\n\n\n\n\n\n","category":"module"},{"location":"api/#Main-entry-point","page":"API reference","title":"Main entry point","text":"","category":"section"},{"location":"api/#ImplicitDifferentiation.ImplicitFunction","page":"API reference","title":"ImplicitDifferentiation.ImplicitFunction","text":"ImplicitFunction\n\nWrapper for an implicit function defined by a solver and a set of conditions which the solution satisfies.\n\nAn ImplicitFunction object behaves like a function, with the following signature:\n\ny, z = (implicit::ImplicitFunction)(x, args...)\n\nThe first output y is differentiable with respect to the first argument x, while the second output z (a byproduct of the solve) and the following positional arguments args are considered constant.\n\nWhen a derivative is queried, the Jacobian of y(x) is computed using the implicit function theorem applied to the conditions c(x, y) (we ignore z for concision):\n\n∂₂c(x, y(x)) * ∂y(x) = -∂₁c(x, y(x))\n\nThis requires solving a linear system A * J = -B where A = ∂₂c, B = ∂₁c and J = ∂y.\n\nConstructor\n\nImplicitFunction(\n    solver,\n    conditions;\n    representation=OperatorRepresentation(),\n    linear_solver=IterativeLinearSolver(),\n    backends=nothing,\n    preparation=nothing,\n    input_example=nothing,\n)\n\nPositional arguments\n\nsolver: a callable returning (x, args...) -> (y, z) where z is an arbitrary byproduct of the solve. Both x and y must be subtypes of AbstractArray, while z and args can be anything.\nconditions: a callable returning a vector of optimality conditions (x, y, z, args...) -> c, must be compatible with automatic differentiation.\n\nKeyword arguments\n\nrepresentation: defines how the partial Jacobian A of the conditions with respect to the output is represented, either MatrixRepresentation or OperatorRepresentation.\nlinear_solver: a callable to solve linear systems with two required methods, one for (A, b::AbstractVector) (single solve) and one for (A, B::AbstractMatrix) (batched solve). It defaults to IterativeLinearSolver but can also be the built-in \\, or a user-provided function.\nbackends::AbstractADType: specifies how the conditions will be differentiated with respect to x and y. It can be either, nothing, which means that the external autodiff system will be used, or a named tuple (; x=AutoSomething(), y=AutoSomethingElse()) of backend objects from ADTypes.jl.\npreparation: either nothing or a mode object from ADTypes.jl: ADTypes.ForwardMode(), ADTypes.ReverseMode() or ADTypes.ForwardOrReverseMode().\ninput_example: either nothing or a tuple (x, args...) used to prepare differentiation.\nstrict::Val=Val(true): whether or not to enforce a strict match in DifferentiationInterface.jl between the preparation and the execution types.\n\n\n\n\n\n","category":"type"},{"location":"api/#Settings","page":"API reference","title":"Settings","text":"","category":"section"},{"location":"api/#ImplicitDifferentiation.MatrixRepresentation","page":"API reference","title":"ImplicitDifferentiation.MatrixRepresentation","text":"MatrixRepresentation\n\nSpecify that the matrix A involved in the implicit function theorem should be represented explicitly, with all its coefficients.\n\nSee also\n\nImplicitFunction\nOperatorRepresentation\n\n\n\n\n\n","category":"type"},{"location":"api/#ImplicitDifferentiation.OperatorRepresentation","page":"API reference","title":"ImplicitDifferentiation.OperatorRepresentation","text":"OperatorRepresentation\n\nSpecify that the matrix A involved in the implicit function theorem should be represented lazily.\n\nConstructors\n\nOperatorRepresentation(; symmetric=false, hermitian=false)\nOperatorRepresentation{package}(; symmetric=false, hermitian=false)\n\nThe type parameter package can be either:\n\n:LinearOperators to use a wrapper from LinearOperators.jl (the default)\n:LinearMaps to use a wrapper from LinearMaps.jl\n\nThe keyword arguments symmetric and hermitian give additional properties of the Jacobian of the conditions with respect to the solution y, in case you can prove them.\n\nSee also\n\nImplicitFunction\nMatrixRepresentation\n\n\n\n\n\n","category":"type"},{"location":"api/#ImplicitDifferentiation.IterativeLinearSolver","page":"API reference","title":"ImplicitDifferentiation.IterativeLinearSolver","text":"IterativeLinearSolver\n\nCallable object that can solve linear systems Ax = b and AX = B in the same way as the built-in \\.\n\nConstructor\n\nIterativeLinearSolver(; kwargs...)\nIterativeLinearSolver{package}(; kwargs...)\n\nThe type parameter package can be either:\n\n:Krylov to use the solver gmres from Krylov.jl (the default)\n:IterativeSolvers to use the solver gmres from IterativeSolvers.jl\n\nKeyword arguments are passed on to the respective solver.\n\nCallable behavior\n\n(::IterativeLinearSolver)(A, b::AbstractVector)\n\nSolve a linear system with a single right-hand side.\n\n(::IterativeLinearSolver)(A, B::AbstractMatrix)\n\nSolve a linear system with multiple right-hand sides.\n\n\n\n\n\n","category":"type"},{"location":"api/#Internals","page":"API reference","title":"Internals","text":"","category":"section"},{"location":"api/#ImplicitDifferentiation.Switch12","page":"API reference","title":"ImplicitDifferentiation.Switch12","text":"Switch12\n\nRepresent a function which behaves like f, except that the first and second arguments are switched:     f(a1, a2, a3) = b becomes     g(a2, a1, a3) = f(a1, a2, a3)\n\n\n\n\n\n","category":"type"},{"location":"api/#ImplicitDifferentiation.VecToVec","page":"API reference","title":"ImplicitDifferentiation.VecToVec","text":"VecToVec\n\nRepresent a function which behaves like f, except that the first argument is expected as a vector, and the return is converted to a vector:     f(a1, a2, a3) = b becomes     g(a1vec, a2, a3) = vec(f(reshape(a1vec, size(a1)), a2, a3))\n\n\n\n\n\n","category":"type"},{"location":"examples/2_advanced/#Advanced-use-cases","page":"Advanced use cases","title":"Advanced use cases","text":"","category":"section"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"We dive into more advanced applications of implicit differentiation.","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"using ForwardDiff\nusing ImplicitDifferentiation\nusing LinearAlgebra\nusing Optim\nusing Zygote","category":"page"},{"location":"examples/2_advanced/#Constrained-optimization","page":"Advanced use cases","title":"Constrained optimization","text":"","category":"section"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"First, we show how to differentiate through the solution of a constrained optimization problem:","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"y(x) = undersety in mathbbR^mmathrmargmin  f(x y) quad textsubject to quad g(x y) leq 0","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"The optimality conditions are a bit trickier than in the previous cases. We can projection on the feasible set mathcalC(x) = y g(x y) leq 0  and exploit the convergence of projected gradient descent with step size eta:","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"y = mathrmproj_mathcalC(x) (y - eta nabla_2 f(x y))","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"To make verification easy, we minimize the following objective:","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"f(x y) = lVert y odot y - x rVert^2","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"on the hypercube mathcalC(x) = 0 1^n. In this case, the optimization problem boils down to a thresholded componentwise square root function, but we implement it using a black box solver from Optim.jl.","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"function forward_cstr_optim(x)\n    f(y) = sum(abs2, y .^ 2 - x)\n    lower = zeros(size(x))\n    upper = ones(size(x))\n    y0 = ones(eltype(x), size(x)) ./ 2\n    res = optimize(f, lower, upper, y0, Fminbox(GradientDescent()))\n    y = Optim.minimizer(res)\n    z = Optim.iterations(res)  # can be useful to retrieve statistics for example\n    return y, z\nend;\nnothing #hide","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"proj_hypercube(p) = max.(0, min.(1, p))\n\nfunction conditions_cstr_optim(x, y, _z)\n    ∇₂f = @. 4 * (y^2 - x) * y\n    η = 0.1\n    return y .- proj_hypercube(y .- η .* ∇₂f)\nend;\nnothing #hide","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"We now have all the ingredients to construct our implicit function.","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"implicit_cstr_optim = ImplicitFunction(forward_cstr_optim, conditions_cstr_optim)","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"And indeed, it behaves as it should when we call it:","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"x = [0.3, 1.4]","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"The second component of x is  1, so its square root will be thresholded to one, and the corresponding derivative will be 0.","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"first(implicit_cstr_optim(x)) .^ 2","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"J_thres = Diagonal([0.5 / sqrt(x[1]), 0])","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"Forward mode autodiff","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"ForwardDiff.jacobian(first ∘ implicit_cstr_optim, x)","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"ForwardDiff.jacobian(first ∘ forward_cstr_optim, x)","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"Reverse mode autodiff","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"Zygote.jacobian(first ∘ implicit_cstr_optim, x)[1]","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"try\n    Zygote.jacobian(first ∘ forward_cstr_optim, x)[1]\ncatch e\n    e\nend","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#ImplicitDifferentiation.jl","page":"Home","title":"ImplicitDifferentiation.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage) (Image: Code Style: Blue) (Image: Aqua QA)","category":"page"},{"location":"","page":"Home","title":"Home","text":"ImplicitDifferentiation.jl is a package for automatic differentiation of functions defined implicitly, i.e., forward mappings","category":"page"},{"location":"","page":"Home","title":"Home","text":"x in mathbbR^n longmapsto y(x) in mathbbR^m","category":"page"},{"location":"","page":"Home","title":"Home","text":"whose output is defined by conditions","category":"page"},{"location":"","page":"Home","title":"Home","text":"c(xy(x)) = 0 in mathbbR^m","category":"page"},{"location":"#Background","page":"Home","title":"Background","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Implicit differentiation is useful to differentiate through two types of functions:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Those for which automatic differentiation fails. Reasons can vary depending on your backend, but the most common include calls to external solvers, mutating operations or type restrictions.\nThose for which automatic differentiation is very slow. A common example is iterative procedures like fixed point equations or optimization algorithms.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you just need a quick overview, check out our JuliaCon 2022 talk. If you want a deeper dive into the theory, you can refer to the paper Efficient and modular implicit differentiation by Blondel et al. (2022).","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install the stable version, open a Julia REPL and run:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg; Pkg.add(\"ImplicitDifferentiation\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"For the latest version, run this instead:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg; Pkg.add(url=\"https://github.com/JuliaDecisionFocusedLearning/ImplicitDifferentiation.jl\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Please read the documentation, especially the examples and FAQ.","category":"page"},{"location":"#Related-projects","page":"Home","title":"Related projects","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In Julia:","category":"page"},{"location":"","page":"Home","title":"Home","text":"SciML ecosystem, especially LinearSolve.jl, NonlinearSolve.jl and Optimization.jl\njump-dev/DiffOpt.jl: differentiation of convex optimization problems\naxelparmentier/InferOpt.jl: approximate differentiation of combinatorial optimization problems\nJuliaNonconvex/NonconvexUtils.jl: contains the original implementation from which this package drew inspiration","category":"page"},{"location":"","page":"Home","title":"Home","text":"In Python:","category":"page"},{"location":"","page":"Home","title":"Home","text":"google/jaxopt: hardware accelerated, batchable and differentiable optimizers in JAX","category":"page"},{"location":"faq/#FAQ","page":"FAQ","title":"FAQ","text":"","category":"section"},{"location":"faq/#Supported-autodiff-backends","page":"FAQ","title":"Supported autodiff backends","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"To differentiate through an ImplicitFunction, the following backends are supported.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Backend Forward mode Reverse mode\nForwardDiff.jl yes -\nChainRules.jl-compatible no yes\nEnzyme.jl soon soon","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"By default, the conditions are differentiated using the same \"outer\" backend that is trying to differentiate the ImplicitFunction. However, this can be switched to any other \"inner\" backend compatible with DifferentiationInterface.jl (i.e. a subtype of ADTypes.AbstractADType).","category":"page"},{"location":"faq/#Input-and-output-types","page":"FAQ","title":"Input and output types","text":"","category":"section"},{"location":"faq/#Arrays","page":"FAQ","title":"Arrays","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Functions that eat or spit out arbitrary arrays are supported, as long as the forward mapping and conditions return arrays of the same size.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"If you deal with small arrays (say, less than 100 elements), consider using StaticArrays.jl for increased performance.","category":"page"},{"location":"faq/#Scalars","page":"FAQ","title":"Scalars","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Functions that eat or spit out a single number are not supported. The forward mapping and conditions need vectors: instead of returning val you should return [val] (a 1-element Vector).","category":"page"},{"location":"faq/#Number-of-inputs-and-outputs","page":"FAQ","title":"Number of inputs and outputs","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Most of the documentation is written for the simple case where the forward mapping is x -> y, i.e. one input and one output. What can you do to handle multiple inputs or outputs? Well, it depends whether you want their derivatives or not.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":" Derivatives needed Derivatives not needed\nMultiple inputs Make x a ComponentVector Supply args... to forward\nMultiple outputs Make y and c two ComponentVectors Let forward return a nontrivial byproduct z","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"We now detail each of these options.","category":"page"},{"location":"faq/#Multiple-inputs-or-outputs-Derivatives-needed","page":"FAQ","title":"Multiple inputs or outputs | Derivatives needed","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Say your forward mapping takes multiple inputs and returns multiple outputs, such that you want derivatives for all of them.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"The trick is to leverage ComponentArrays.jl to wrap all the inputs inside a single a ComponentVector, and do the same for all the outputs. See the examples for a demonstration.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"warning: Warning\nThe default linear operator representation does not support ComponentArrays.jl: you need to select representation=OperatorRepresentation{:LinearMaps}() in the ImplicitFunction constructor for it to work.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"warning: Warning\nYou may run into issues trying to differentiate through the ComponentVector constructor. For instance, Zygote.jl will throw ERROR: Mutating arrays is not supported. Check out this issue for a dirty workaround involving custom chain rules for the constructor.","category":"page"},{"location":"faq/#Multiple-inputs-Derivatives-not-needed","page":"FAQ","title":"Multiple inputs | Derivatives not needed","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"If your forward mapping (or conditions) takes multiple inputs but you don't care about derivatives, then you can add further positional arguments beyond x. It is important to make sure that the forward mapping and conditions accept the same set of arguments, even if each of these functions only uses a subset of them.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"forward(x, arg1, arg2) = y, z\nconditions(x, y, z, arg1, arg2) = c","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"All of the positional arguments apart from x will get zero tangents during differentiation of the implicit function.","category":"page"},{"location":"faq/#Multiple-outputs-Derivatives-not-needed","page":"FAQ","title":"Multiple outputs | Derivatives not needed","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"The last and most tricky situation is when your forward mapping returns multiple outputs, but you only care about some of their derivatives. Then, you need to group the objects you don't want to differentiate into a nontrivial \"byproduct\" z, returned alongside the actual output y. This way, derivatives of z will not be computed: the byproduct is considered constant during differentiation.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"This is mainly useful when the solution procedure creates objects such as Jacobians, which we want to reuse when computing or differentiating the conditions. In that case, you may want to write the conditions differentiation rules yourself. A more advanced application is given by DifferentiableFrankWolfe.jl.","category":"page"},{"location":"faq/#Modeling-tips","page":"FAQ","title":"Modeling tips","text":"","category":"section"},{"location":"faq/#Writing-conditions","page":"FAQ","title":"Writing conditions","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"We recommend that the conditions themselves do not involve calls to autodiff, even when they describe a gradient. Otherwise, you will need to make sure that nested autodiff works well in your case (i.e. that the \"outer\" backend can differentiate through the \"inner\" backend). For instance, if you're differentiating your implicit function (and your conditions) in reverse mode with Zygote.jl, you may want to use ForwardDiff.jl mode to compute gradients inside the conditions.","category":"page"},{"location":"faq/#Dealing-with-constraints","page":"FAQ","title":"Dealing with constraints","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"To express constrained optimization problems as implicit functions, you might need differentiable projections or proximal operators to write the optimality conditions. See Efficient and modular implicit differentiation for precise formulations.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"In case these operators are too complicated to code them yourself, here are a few places you can look:","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"MathOptSetDistances.jl\nProximalOperators.jl","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"An alternative is differentiating through the KKT conditions, which is exactly what DiffOpt.jl does for JuMP models.","category":"page"},{"location":"faq/#Memoization","page":"FAQ","title":"Memoization","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"In some cases, performance might be increased by using memoization to prevent redundant calls to forward. For instance, this is relevant when calculating large Jacobians with forward differentiation, where the computation happens in chunks. Packages such as Memoize.jl and Memoization.jl are useful for defining a memoized version of forward:","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"using Memoize\n@memoize Dict forward(x, args...; kwargs...) = y, z","category":"page"},{"location":"examples/1_basic/#Basic-use-cases","page":"Basic use cases","title":"Basic use cases","text":"","category":"section"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"We show how to differentiate through very common routines:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"an unconstrained optimization problem\na nonlinear system of equations\na fixed point iteration","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Note that some packages from the SciML ecosystem provide a similar implicit differentiation mechanism.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"using ForwardDiff\nusing ImplicitDifferentiation\nusing LinearAlgebra\nusing NLsolve\nusing Optim\nusing Zygote","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In all three cases, we will use the square root as our forward mapping, but expressed in three different ways. Here's our heroic test vector:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"x = [4.0, 9.0];\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Since we already know the mathematical expression of the Jacobian, we will be able to compare it with our numerical results.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"J = Diagonal(0.5 ./ sqrt.(x))","category":"page"},{"location":"examples/1_basic/#Unconstrained-optimization","page":"Basic use cases","title":"Unconstrained optimization","text":"","category":"section"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"First, we show how to differentiate through the solution of an unconstrained optimization problem:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"y(x) = undersety in mathbbR^mmathrmargmin  f(x y)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"The optimality conditions are given by gradient stationarity:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"c(x y) = nabla_2 f(x y) = 0","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"To make verification easy, we minimize the following objective:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"f(x y) = lVert y odot y - x rVert^2","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In this case, the optimization problem boils down to the componentwise square root function, but we implement it using a black box solver from Optim.jl. Note the presence of an additional positional argument, which is not differentiated.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function forward_optim(x, method)\n    f(y) = sum(abs2, y .^ 2 .- x)\n    y0 = ones(eltype(x), size(x))\n    result = optimize(f, y0, method)\n    y = Optim.minimizer(result)\n    z = nothing\n    return y, z\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Even though they are defined as a gradient, it is better to provide optimality conditions explicitly: that way we avoid nesting autodiff calls. By default, the conditions should accept two arguments as input. The forward mapping and the conditions should accept the same set of positional arguments.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function conditions_optim(x, y, _z, _method)\n    ∇₂f = 4 .* (y .^ 2 .- x) .* y\n    return ∇₂f\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"We now have all the ingredients to construct our implicit function.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"implicit_optim = ImplicitFunction(forward_optim, conditions_optim)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"And indeed, it behaves as it should when we call it:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"first(implicit_optim(x, LBFGS())) .^ 2","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Forward mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> first(implicit_optim(_x, LBFGS())), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In this instance, we could use ForwardDiff.jl directly on the solver:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> first(forward_optim(_x, LBFGS())), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Reverse mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Zygote.jacobian(_x -> first(implicit_optim(_x, LBFGS())), x)[1]","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In this instance, we cannot use Zygote.jl directly on the solver (due to unsupported try/catch statements).","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"try\n    Zygote.jacobian(_x -> first(forward_optim(_x, LBFGS())), x)[1]\ncatch e\n    e\nend","category":"page"},{"location":"examples/1_basic/#Nonlinear-system","page":"Basic use cases","title":"Nonlinear system","text":"","category":"section"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Next, we show how to differentiate through the solution of a nonlinear system of equations:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"textfind quad y(x) quad textsuch that quad c(x y(x)) = 0","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"The optimality conditions are pretty obvious:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"c(x y) = 0","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"To make verification easy, we solve the following system:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"c(x y) = y odot y - x = 0","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In this case, the optimization problem boils down to the componentwise square root function, but we implement it using a black box solver from NLsolve.jl.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function forward_nlsolve(x, method)\n    F!(storage, y) = (storage .= y .^ 2 .- x)\n    initial_y = similar(x)\n    initial_y .= 1\n    result = nlsolve(F!, initial_y; method)\n    y = result.zero\n    z = nothing\n    return y, z\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function conditions_nlsolve(x, y, _z, _method)\n    c = y .^ 2 .- x\n    return c\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"implicit_nlsolve = ImplicitFunction(forward_nlsolve, conditions_nlsolve)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"first(implicit_nlsolve(x, :newton)) .^ 2","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Forward mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> first(implicit_nlsolve(_x, :newton)), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> first(forward_nlsolve(_x, :newton)), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Reverse mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Zygote.jacobian(_x -> first(implicit_nlsolve(_x, :newton)), x)[1]","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"try\n    Zygote.jacobian(_x -> first(forward_nlsolve(_x, :newton)), x)[1]\ncatch e\n    e\nend","category":"page"},{"location":"examples/1_basic/#Fixed-point","page":"Basic use cases","title":"Fixed point","text":"","category":"section"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Finally, we show how to differentiate through the limit of a fixed point iteration:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"y longmapsto g(x y)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"The optimality conditions are pretty obvious:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"c(x y) = g(x y) - y = 0","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"To make verification easy, we consider Heron's method:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"g(x y) = frac12 left(y + fracxyright)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In this case, the fixed point algorithm boils down to the componentwise square root function, but we implement it manually.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function forward_fixedpoint(x, iterations)\n    y = ones(eltype(x), size(x))\n    for _ in 1:iterations\n        y .= (y .+ x ./ y) ./ 2\n    end\n    z = nothing\n    return y, z\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function conditions_fixedpoint(x, y, _z, _iterations)\n    g = (y .+ x ./ y) ./ 2\n    return g .- y\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"implicit_fixedpoint = ImplicitFunction(forward_fixedpoint, conditions_fixedpoint)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"first(implicit_fixedpoint(x, 10)) .^ 2","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Forward mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> first(implicit_fixedpoint(_x, 10)), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> first(forward_fixedpoint(_x, 10)), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Reverse mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Zygote.jacobian(_x -> first(implicit_fixedpoint(_x, 10)), x)[1]","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"try\n    Zygote.jacobian(_x -> first(forward_fixedpoint(_x, 10)), x)[1]\ncatch e\n    e\nend","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"This page was generated using Literate.jl.","category":"page"}]
}
