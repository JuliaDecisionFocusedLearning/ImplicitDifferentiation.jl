var documenterSearchIndex = {"docs":
[{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"EditURL = \"../../../examples/0_intro.jl\"","category":"page"},{"location":"examples/0_intro/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"We explain the basics of our package on a simple function that is not amenable to naive automatic differentiation.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"using ForwardDiff\nusing ImplicitDifferentiation\nusing LinearAlgebra\nusing Zygote","category":"page"},{"location":"examples/0_intro/#Why-do-we-bother?","page":"Introduction","title":"Why do we bother?","text":"","category":"section"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"ForwardDiff.jl and Zygote.jl are two prominent packages for automatic differentiation in Julia. While they are very generic, there are simple language constructs that they cannot differentiate through.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"function badsqrt(x::AbstractArray)\n    a = [0.0]\n    a[1] = x[1]\n    return sqrt.(x)\nend;\nnothing #hide","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"This is essentially the componentwise square root function but with an additional twist: a::Vector{Float64} is created internally, and its only element is replaced with the first element of x. We can check that it does what it's supposed to do.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"x = [4.0, 9.0]\nbadsqrt(x)","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Of course the Jacobian has an explicit formula.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"J = Diagonal(0.5 ./ sqrt.(x))","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"However, things start to go wrong when we compute it with autodiff, due to the limitations of ForwardDiff.jl and those of Zygote.jl.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"try\n    ForwardDiff.jacobian(badsqrt, x)\ncatch e\n    e\nend","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"ForwardDiff.jl throws an error because it tries to call badsqrt with an array of dual numbers, and cannot use one of these numbers to fill a (which has element type Float64).","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"try\n    Zygote.jacobian(badsqrt, x)\ncatch e\n    e\nend","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Zygote.jl also throws an error because it cannot handle mutation.","category":"page"},{"location":"examples/0_intro/#Implicit-function","page":"Introduction","title":"Implicit function","text":"","category":"section"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"The first possible use of ImplicitDifferentiation.jl is to overcome the limitations of automatic differentiation packages by defining functions (and computing their derivatives) implicitly. An implicit function is a mapping","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"x in mathbbR^n longmapsto y(x) in mathbbR^m","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"whose output is defined by conditions","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"c(xy(x)) = 0 in mathbbR^m","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"We represent it using a type called ImplicitFunction, which you will see in action shortly.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"First we define a forward mapping corresponding to the function we consider. It returns the actual output y(x) of the function, and can be thought of as a black box solver. Importantly, this Julia callable doesn't need to be differentiable by automatic differentiation packages but the underlying function still needs to be mathematically differentiable.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"forward(x) = badsqrt(x);\nnothing #hide","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Then we define conditions c(x y) = 0 that the output y(x) is supposed to satisfy. These conditions must be array-valued, with the same size as y. Unlike the forward mapping, the conditions need to be differentiable by automatic differentiation packages with respect to both x and y. Here the conditions are very obvious: the square of the square root should be equal to the original value.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"function conditions(x, y)\n    c = y .^ 2 .- x\n    return c\nend;\nnothing #hide","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Finally, we construct a wrapper implicit around the previous objects. By default, forward is assumed to return a single output and conditions is assumed to accept 2 arguments.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"implicit = ImplicitFunction(forward, conditions)","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"What does this wrapper do? When we call it as a function, it just falls back on implicit.forward, so unsurprisingly we get the output y(x).","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"implicit(x)","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"And when we try to compute its Jacobian, the implicit function theorem is applied in the background to circumvent the lack of differentiability of the forward mapping.","category":"page"},{"location":"examples/0_intro/#Forward-and-reverse-mode-autodiff","page":"Introduction","title":"Forward and reverse mode autodiff","text":"","category":"section"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Now ForwardDiff.jl works seamlessly.","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"ForwardDiff.jacobian(implicit, x) ≈ J","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"And so does Zygote.jl. Hurray!","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"Zygote.jacobian(implicit, x)[1] ≈ J","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"","category":"page"},{"location":"examples/0_intro/","page":"Introduction","title":"Introduction","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"EditURL = \"../../../examples/3_tricks.jl\"","category":"page"},{"location":"examples/3_tricks/#Tricks","page":"Tricks","title":"Tricks","text":"","category":"section"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"We demonstrate several features that may come in handy for some users.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"using ComponentArrays\nusing ForwardDiff\nusing ImplicitDifferentiation\nusing Krylov\nusing LinearAlgebra\nusing Zygote","category":"page"},{"location":"examples/3_tricks/#ComponentArrays","page":"Tricks","title":"ComponentArrays","text":"","category":"section"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"For when you need derivatives with respect to multiple inputs or outputs.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"function forward_components_aux(a::AbstractVector, b::AbstractVector, m::Number)\n    d = m * sqrt.(a)\n    e = sqrt.(b)\n    return d, e\nend\n\nfunction conditions_components_aux(a, b, m, d, e)\n    c_d = (d ./ m) .^ 2 .- a\n    c_e = (e .^ 2) .- b\n    return c_d, c_e\nend;\nnothing #hide","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"You can use ComponentVector from ComponentArrays.jl as an intermediate storage.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"function forward_components(x::ComponentVector)\n    d, e = forward_components_aux(x.a, x.b, x.m)\n    y = ComponentVector(; d=d, e=e)\n    return y\nend\n\nfunction conditions_components(x::ComponentVector, y::ComponentVector)\n    c_d, c_e = conditions_components_aux(x.a, x.b, x.m, y.d, y.e)\n    c = ComponentVector(; c_d=c_d, c_e=c_e)\n    return c\nend;\nnothing #hide","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"And build your implicit function like so.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"implicit_components = ImplicitFunction(forward_components, conditions_components);\nnothing #hide","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"Since ComponentVectors are not yet compatible with iterative solvers from Krylov.jl, we (temporarily) need a bit of type piracy to make it work","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"Krylov.ktypeof(::ComponentVector{T,V}) where {T,V} = V","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"Now we're good to go.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"a, b, m = [1.0, 2.0], [3.0, 4.0, 5.0], 6.0\nx = ComponentVector(; a=a, b=b, m=m)\nimplicit_components(x)","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"And it works with both ForwardDiff.jl and Zygote.jl","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"ForwardDiff.jacobian(implicit_components, x)","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"Zygote.jacobian(implicit_components, x)[1]","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"function full_pipeline(a, b, m)\n    x = ComponentVector(; a=a, b=b, m=m)\n    y = implicit_components(x)\n    return y.d, y.e\nend;\nnothing #hide","category":"page"},{"location":"examples/3_tricks/#Byproducts","page":"Tricks","title":"Byproducts","text":"","category":"section"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"For when you need an additional output but don't care about its derivative.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"function forward_byproduct(x)\n    z = 2  # \"randomized\" choice\n    y = x .^ (1 / z)\n    return y, z\nend\n\nfunction conditions_byproduct(x, y, z)\n    c = y .^ z .- x\n    return c\nend;\nnothing #hide","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"The syntax for building the implicit function is the same.","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"implicit_byproduct = ImplicitFunction(forward_byproduct, conditions_byproduct);\nnothing #hide","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"But this time the return value is a tuple (y, z)","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"x = [4.0, 9.0]\nimplicit_byproduct(x)","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"And it works with both ForwardDiff.jl and Zygote.jl","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"ForwardDiff.jacobian(first ∘ implicit_byproduct, x)","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"Zygote.jacobian(first ∘ implicit_byproduct, x)[1]","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"","category":"page"},{"location":"examples/3_tricks/","page":"Tricks","title":"Tricks","text":"This page was generated using Literate.jl.","category":"page"},{"location":"api/","page":"API reference","title":"API reference","text":"CurrentModule = ImplicitDifferentiation\nCollapsedDocStrings = true","category":"page"},{"location":"api/#API-reference","page":"API reference","title":"API reference","text":"","category":"section"},{"location":"api/#Public","page":"API reference","title":"Public","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules = [ImplicitDifferentiation]\nPrivate = false","category":"page"},{"location":"api/#ImplicitDifferentiation.ImplicitDifferentiation","page":"API reference","title":"ImplicitDifferentiation.ImplicitDifferentiation","text":"ImplicitDifferentiation\n\nA Julia package for automatic differentiation of implicit functions.\n\nIts main export is the type ImplicitFunction.\n\n\n\n\n\n","category":"module"},{"location":"api/#ImplicitDifferentiation.ImplicitFunction","page":"API reference","title":"ImplicitDifferentiation.ImplicitFunction","text":"ImplicitFunction{lazy}\n\nWrapper for an implicit function defined by a forward mapping y and a set of conditions c.\n\nAn ImplicitFunction object behaves like a function, and every call is differentiable with respect to the first argument x. When a derivative is queried, the Jacobian of y is computed using the implicit function theorem:\n\n∂/∂y c(x, y(x)) * ∂/∂x y(x) = -∂/∂x c(x, y(x))\n\nThis requires solving a linear system A * J = -B where A = ∂c/∂y, B = ∂c/∂x and J = ∂y/∂x.\n\nType parameters\n\nlazy::Bool: whether to represent A and B with a LinearOperator from LinearOperators.jl (lazy = true) or a dense Jacobian matrix (lazy = false)\n\nUsually, dense Jacobians are more efficient in small dimension, while lazy operators become necessary in high dimension. The value of lazy must be chosen together with the linear_solver, see below.\n\nFields\n\nforward: a callable computing y(x), does not need to be compatible with automatic differentiation\nconditions: a callable computing c(x, y), must be compatible with automatic differentiation\nlinear_solver: a callable to solve the linear system\nconditions_x_backend: how the conditions will be differentiated w.r.t. the first argument x \nconditions_y_backend: how the conditions will be differentiated w.r.t. the second argument y \n\nConstructors\n\nImplicitFunction(\n    forward, conditions;\n    linear_solver=KrylovLinearSolver(),\n    conditions_x_backend=nothing,\n    conditions_x_backend=nothing,\n)\n\nPicks the lazy parameter automatically based on the linear_solver, using the following heuristic: lazy = linear_solver != \\.\n\nImplicitFunction{lazy}(\n    forward, conditions;\n    linear_solver=lazy ? KrylovLinearSolver() : \\,\n    conditions_x_backend=nothing,\n    conditions_y_backend=nothing,\n)\n\nPicks the linear_solver automatically based on the lazy parameter.\n\nCallable behavior\n\n(implicit::ImplicitFunction)(x::AbstractVector, args...; kwargs...)\n\nReturn implicit.forward(x, args...; kwargs...), which can be either an AbstractVector y or a tuple (y, z).\n\nThis call makes y differentiable with respect to x.\n\nFunction signatures\n\nThere are two possible signatures for forward and conditions, which must be consistent with one another:\n\nstandard byproduct\nforward(x, args...; kwargs...) = y conditions(x, y, args...; kwargs...) = c\nforward(x, args...; kwargs...) = (y, z) conditions(x, y, z, args...; kwargs...) = c\n\nIn both cases, x, y and c must be AbstractVectors, with length(y) = length(c). In the second case, the byproduct z can be an arbitrary object generated by forward. The positional arguments args... and keyword arguments kwargs... must be the same for both forward and conditions.\n\nThe byproduct z and the other positional arguments args... beyond x are considered constant for differentiation purposes.\n\nLinear solver\n\nThe provided linear_solver objects needs to be callable, with two methods:\n\n(A, b::AbstractVector) -> s::AbstractVector such that A * s = b\n(A, B::AbstractMatrix) -> S::AbstractMatrix such that A * S = B\n\nIt can be either a direct solver (like \\) or an iterative one (like KrylovLinearSolver). Typically, direct solvers work best with dense Jacobians (lazy = false) while iterative solvers work best with operators (lazy = true).\n\nCondition backends\n\nThe provided conditions_x_backend and conditions_y_backend can be either:\n\nnothing (the default), in which case the outer backend (the one differentiating through the ImplicitFunction) is used.\nan object subtyping AbstractADType from ADTypes.jl;\n\nWhen differentiating with Enzyme as an outer backend, the default setting assumes that conditions does not contain writeable data involved in derivatives.\n\n\n\n\n\n","category":"type"},{"location":"api/#ImplicitDifferentiation.KrylovLinearSolver","page":"API reference","title":"ImplicitDifferentiation.KrylovLinearSolver","text":"KrylovLinearSolver\n\nCallable object that can solve linear systems Ax = b and AX = B in the same way as the built-in \\. Uses an iterative solver from Krylov.jl under the hood.\n\nConstructor\n\nKrylovLinearSolver(; verbose=true)\n\nIf verbose is true, the solver logs a warning in case of failure. Otherwise it will fail silently, and may return solutions that do not exactly satisfy the linear system.\n\nCallable behavior\n\n(::KylovLinearSolver)(A, b::AbstractVector)\n\nSolve a linear system with a single right-hand side.\n\n(::KrylovLinearSolver)(A, B::AbstractMatrix)\n\nSolve a linear system with multiple right-hand sides.\n\n\n\n\n\n","category":"type"},{"location":"api/#Internals","page":"API reference","title":"Internals","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules = [ImplicitDifferentiation]\nPublic = false","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"EditURL = \"../../../examples/2_advanced.jl\"","category":"page"},{"location":"examples/2_advanced/#Advanced-use-cases","page":"Advanced use cases","title":"Advanced use cases","text":"","category":"section"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"We dive into more advanced applications of implicit differentiation.","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"using ForwardDiff\nusing ImplicitDifferentiation\nusing LinearAlgebra\nusing Optim\nusing Zygote","category":"page"},{"location":"examples/2_advanced/#Constrained-optimization","page":"Advanced use cases","title":"Constrained optimization","text":"","category":"section"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"First, we show how to differentiate through the solution of a constrained optimization problem:","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"y(x) = undersety in mathbbR^mmathrmargmin  f(x y) quad textsubject to quad g(x y) leq 0","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"The optimality conditions are a bit trickier than in the previous cases. We can projection on the feasible set mathcalC(x) = y g(x y) leq 0  and exploit the convergence of projected gradient descent with step size eta:","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"y = mathrmproj_mathcalC(x) (y - eta nabla_2 f(x y))","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"To make verification easy, we minimize the following objective:","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"f(x y) = lVert y odot y - x rVert^2","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"on the hypercube mathcalC(x) = 0 1^n. In this case, the optimization problem boils down to a thresholded componentwise square root function, but we implement it using a black box solver from Optim.jl.","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"function forward_cstr_optim(x)\n    f(y) = sum(abs2, y .^ 2 - x)\n    lower = zeros(size(x))\n    upper = ones(size(x))\n    y0 = ones(eltype(x), size(x)) ./ 2\n    res = optimize(f, lower, upper, y0, Fminbox(GradientDescent()))\n    y = Optim.minimizer(res)\n    return y\nend;\nnothing #hide","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"proj_hypercube(p) = max.(0, min.(1, p))\n\nfunction conditions_cstr_optim(x, y)\n    ∇₂f = @. 4 * (y^2 - x) * y\n    η = 0.1\n    return y .- proj_hypercube(y .- η .* ∇₂f)\nend;\nnothing #hide","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"We now have all the ingredients to construct our implicit function.","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"implicit_cstr_optim = ImplicitFunction(forward_cstr_optim, conditions_cstr_optim)","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"And indeed, it behaves as it should when we call it:","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"x = [0.3, 1.4]","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"The second component of x is  1, so its square root will be thresholded to one, and the corresponding derivative will be 0.","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"implicit_cstr_optim(x) .^ 2","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"J_thres = Diagonal([0.5 / sqrt(x[1]), 0])","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"Forward mode autodiff","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"ForwardDiff.jacobian(implicit_cstr_optim, x)","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"ForwardDiff.jacobian(forward_cstr_optim, x)","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"Reverse mode autodiff","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"Zygote.jacobian(implicit_cstr_optim, x)[1]","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"try\n    Zygote.jacobian(forward_cstr_optim, x)[1]\ncatch e\n    e\nend","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"","category":"page"},{"location":"examples/2_advanced/","page":"Advanced use cases","title":"Advanced use cases","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#ImplicitDifferentiation.jl","page":"Home","title":"ImplicitDifferentiation.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Stable) (Image: Dev) (Image: Build Status) (Image: Coverage) (Image: Code Style: Blue) (Image: Aqua QA)","category":"page"},{"location":"","page":"Home","title":"Home","text":"ImplicitDifferentiation.jl is a package for automatic differentiation of functions defined implicitly, i.e., forward mappings","category":"page"},{"location":"","page":"Home","title":"Home","text":"x in mathbbR^n longmapsto y(x) in mathbbR^m","category":"page"},{"location":"","page":"Home","title":"Home","text":"whose output is defined by conditions","category":"page"},{"location":"","page":"Home","title":"Home","text":"c(xy(x)) = 0 in mathbbR^m","category":"page"},{"location":"#Background","page":"Home","title":"Background","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Implicit differentiation is useful to differentiate through two types of functions:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Those for which automatic differentiation fails. Reasons can vary depending on your backend, but the most common include calls to external solvers, mutating operations or type restrictions.\nThose for which automatic differentiation is very slow. A common example is iterative procedures like fixed point equations or optimization algorithms.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you just need a quick overview, check out our JuliaCon 2022 talk. If you want a deeper dive into the theory, you can refer to the paper Efficient and modular implicit differentiation by Blondel et al. (2022).","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install the stable version, open a Julia REPL and run:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg; Pkg.add(\"ImplicitDifferentiation\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"For the latest version, run this instead:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg; Pkg.add(url=\"https://github.com/JuliaDecisionFocusedLearning/ImplicitDifferentiation.jl\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Please read the documentation, especially the examples and FAQ.","category":"page"},{"location":"#Related-projects","page":"Home","title":"Related projects","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In Julia:","category":"page"},{"location":"","page":"Home","title":"Home","text":"SciML ecosystem, especially LinearSolve.jl, NonlinearSolve.jl and Optimization.jl\njump-dev/DiffOpt.jl: differentiation of convex optimization problems\naxelparmentier/InferOpt.jl: approximate differentiation of combinatorial optimization problems\nJuliaNonconvex/NonconvexUtils.jl: contains the original implementation from which this package drew inspiration","category":"page"},{"location":"","page":"Home","title":"Home","text":"In Python:","category":"page"},{"location":"","page":"Home","title":"Home","text":"google/jaxopt: hardware accelerated, batchable and differentiable optimizers in JAX","category":"page"},{"location":"faq/#FAQ","page":"FAQ","title":"FAQ","text":"","category":"section"},{"location":"faq/#Supported-autodiff-backends","page":"FAQ","title":"Supported autodiff backends","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"To differentiate through an ImplicitFunction, the following backends are supported.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Backend Forward mode Reverse mode\nForwardDiff.jl yes -\nChainRules.jl-compatible no yes\nEnzyme.jl yes soon","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"By default, the conditions are differentiated using the same \"outer\" backend that is trying to differentiate the ImplicitFunction. However, this can be switched to any other \"inner\" backend compatible with DifferentiationInterface.jl (i.e. a subtype of ADTypes.AbstractADType).","category":"page"},{"location":"faq/#Input-and-output-types","page":"FAQ","title":"Input and output types","text":"","category":"section"},{"location":"faq/#Vectors","page":"FAQ","title":"Vectors","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Functions that eat or spit out arbitrary vectors are supported, as long as the forward mapping and conditions return vectors of the same size.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"If you deal with small vectors (say, less than 100 elements), consider using StaticArrays.jl for increased performance.","category":"page"},{"location":"faq/#Arrays","page":"FAQ","title":"Arrays","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Functions that eat or spit out matrices and higher-order tensors are not supported. You can use vec and reshape for the conversion to and from vectors.","category":"page"},{"location":"faq/#Scalars","page":"FAQ","title":"Scalars","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Functions that eat or spit out a single number are not supported. The forward mapping and conditions need vectors: instead of returning val you should return [val] (a 1-element Vector). Or better yet, wrap it in a static vector: SVector(val).","category":"page"},{"location":"faq/#Sparse-arrays","page":"FAQ","title":"Sparse arrays","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"danger: Danger\nSparse arrays are not supported out of the box and might yield incorrect values!","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"If your use case involves sparse arrays, it is best to differentiate with respect to the dense vector of values and only construct the sparse array inside of the forward and conditions functions.","category":"page"},{"location":"faq/#Number-of-inputs-and-outputs","page":"FAQ","title":"Number of inputs and outputs","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Most of the documentation is written for the simple case where the forward mapping is x -> y, i.e. one input and one output. What can you do to handle multiple inputs or outputs? Well, it depends whether you want their derivatives or not.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":" Derivatives needed Derivatives not needed\nMultiple inputs Make x a ComponentVector Supply args and kwargs to forward\nMultiple outputs Make y and c two ComponentVectors Let forward return a byproduct z","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"We now detail each of these options.","category":"page"},{"location":"faq/#Multiple-inputs-or-outputs-Derivatives-needed","page":"FAQ","title":"Multiple inputs or outputs | Derivatives needed","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Say your forward mapping takes multiple inputs and returns multiple outputs, such that you want derivatives for all of them.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"The trick is to leverage ComponentArrays.jl to wrap all the inputs inside a single a ComponentVector, and do the same for all the outputs. See the examples for a demonstration.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"warning: Warning\nYou may run into issues trying to differentiate through the ComponentVector constructor. For instance, Zygote.jl will throw ERROR: Mutating arrays is not supported. Check out this issue for a dirty workaround involving custom chain rules for the constructor.","category":"page"},{"location":"faq/#Multiple-inputs-Derivatives-not-needed","page":"FAQ","title":"Multiple inputs | Derivatives not needed","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"If your forward mapping (or conditions) takes multiple inputs but you don't care about derivatives, then you can add further positional and keyword arguments beyond x. It is important to make sure that the forward mapping and conditions accept the same set of arguments, even if each of these functions only uses a subset of them.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"forward(x, arg1, arg2; kwarg1, kwarg2) = y\nconditions(x, y, arg1, arg2; kwarg1, kwarg2) = c","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"All of the positional and keyword arguments apart from x will get zero tangents during differentiation of the implicit function.","category":"page"},{"location":"faq/#Multiple-outputs-Derivatives-not-needed","page":"FAQ","title":"Multiple outputs | Derivatives not needed","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"The last and most tricky situation is when your forward mapping returns multiple outputs, but you only care about some of their derivatives. Then, you need to group the objects you don't want to differentiate into a \"byproduct\" z, returned alongside the actual output y. This way, derivatives of z will not be computed: the byproduct is considered constant during differentiation.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"The signatures of your functions will need to be be slightly different from the previous cases:","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"forward(x, arg1, arg2; kwarg1, kwarg2) = (y, z)\nconditions(x, y, z, arg1, arg2; kwarg1, kwarg2) =  c","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"See the examples for a demonstration.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"This is mainly useful when the solution procedure creates objects such as Jacobians, which we want to reuse when computing or differentiating the conditions. In that case, you may want to write the conditions differentiation rules yourself. A more advanced application is given by DifferentiableFrankWolfe.jl.","category":"page"},{"location":"faq/#Modeling-tips","page":"FAQ","title":"Modeling tips","text":"","category":"section"},{"location":"faq/#Writing-conditions","page":"FAQ","title":"Writing conditions","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"We recommend that the conditions themselves do not involve calls to autodiff, even when they describe a gradient. Otherwise, you will need to make sure that nested autodiff works well in your case (i.e. that the \"outer\" backend can differentiate through the \"inner\" backend). For instance, if you're differentiating your implicit function (and your conditions) in reverse mode with Zygote.jl, you may want to use ForwardDiff.jl mode to compute gradients inside the conditions.","category":"page"},{"location":"faq/#Dealing-with-constraints","page":"FAQ","title":"Dealing with constraints","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"To express constrained optimization problems as implicit functions, you might need differentiable projections or proximal operators to write the optimality conditions. See Efficient and modular implicit differentiation for precise formulations.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"In case these operators are too complicated to code them yourself, here are a few places you can look:","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"MathOptSetDistances.jl\nProximalOperators.jl","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"An alternative is differentiating through the KKT conditions, which is exactly what DiffOpt.jl does for JuMP models.","category":"page"},{"location":"faq/#Memoization","page":"FAQ","title":"Memoization","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"In some cases, performance might be increased by using memoization to prevent redundant calls to forward. For instance, this is relevant when calculating large Jacobians with forward differentiation, where the computation happens in chunks. Packages such as Memoize.jl and Memoization.jl are useful for defining a memoized version of forward:","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"using Memoize\n@memoize Dict forward(x, args...; kwargs...) = y","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"EditURL = \"../../../examples/1_basic.jl\"","category":"page"},{"location":"examples/1_basic/#Basic-use-cases","page":"Basic use cases","title":"Basic use cases","text":"","category":"section"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"We show how to differentiate through very common routines:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"an unconstrained optimization problem\na nonlinear system of equations\na fixed point iteration","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Note that some packages from the SciML ecosystem provide a similar implicit differentiation mechanism.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"using ForwardDiff\nusing ImplicitDifferentiation\nusing LinearAlgebra\nusing NLsolve\nusing Optim\nusing Zygote","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In all three cases, we will use the square root as our forward mapping, but expressed in three different ways. Here's our heroic test vector:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"x = [4.0, 9.0];\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Since we already know the mathematical expression of the Jacobian, we will be able to compare it with our numerical results.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"J = Diagonal(0.5 ./ sqrt.(x))","category":"page"},{"location":"examples/1_basic/#Unconstrained-optimization","page":"Basic use cases","title":"Unconstrained optimization","text":"","category":"section"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"First, we show how to differentiate through the solution of an unconstrained optimization problem:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"y(x) = undersety in mathbbR^mmathrmargmin  f(x y)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"The optimality conditions are given by gradient stationarity:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"c(x y) = nabla_2 f(x y) = 0","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"To make verification easy, we minimize the following objective:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"f(x y) = lVert y odot y - x rVert^2","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In this case, the optimization problem boils down to the componentwise square root function, but we implement it using a black box solver from Optim.jl. Note the presence of a keyword argument.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function forward_optim(x; method)\n    f(y) = sum(abs2, y .^ 2 .- x)\n    y0 = ones(eltype(x), size(x))\n    result = optimize(f, y0, method)\n    return Optim.minimizer(result)\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Even though they are defined as a gradient, it is better to provide optimality conditions explicitly: that way we avoid nesting autodiff calls. By default, the conditions should accept two arguments as input. The forward mapping and the conditions should accept the same set of keyword arguments.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function conditions_optim(x, y; method)\n    ∇₂f = @. 4 * (y^2 - x) * y\n    return ∇₂f\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"We now have all the ingredients to construct our implicit function.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"implicit_optim = ImplicitFunction(forward_optim, conditions_optim)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"And indeed, it behaves as it should when we call it:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"implicit_optim(x; method=LBFGS()) .^ 2","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Forward mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> implicit_optim(_x; method=LBFGS()), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In this instance, we could use ForwardDiff.jl directly on the solver:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> forward_optim(_x; method=LBFGS()), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Reverse mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Zygote.jacobian(_x -> implicit_optim(_x; method=LBFGS()), x)[1]","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In this instance, we cannot use Zygote.jl directly on the solver (due to unsupported try/catch statements).","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"try\n    Zygote.jacobian(_x -> forward_optim(_x; method=LBFGS()), x)[1]\ncatch e\n    e\nend","category":"page"},{"location":"examples/1_basic/#Nonlinear-system","page":"Basic use cases","title":"Nonlinear system","text":"","category":"section"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Next, we show how to differentiate through the solution of a nonlinear system of equations:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"textfind quad y(x) quad textsuch that quad c(x y(x)) = 0","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"The optimality conditions are pretty obvious:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"c(x y) = 0","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"To make verification easy, we solve the following system:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"c(x y) = y odot y - x = 0","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In this case, the optimization problem boils down to the componentwise square root function, but we implement it using a black box solver from NLsolve.jl.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function forward_nlsolve(x; method)\n    F!(storage, y) = (storage .= y .^ 2 .- x)\n    initial_y = similar(x)\n    initial_y .= 1\n    result = nlsolve(F!, initial_y; method)\n    return result.zero\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function conditions_nlsolve(x, y; method)\n    c = y .^ 2 .- x\n    return c\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"implicit_nlsolve = ImplicitFunction(forward_nlsolve, conditions_nlsolve)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"implicit_nlsolve(x; method=:newton) .^ 2","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Forward mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> implicit_nlsolve(_x; method=:newton), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> forward_nlsolve(_x; method=:newton), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Reverse mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Zygote.jacobian(_x -> implicit_nlsolve(_x; method=:newton), x)[1]","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"try\n    Zygote.jacobian(_x -> forward_nlsolve(_x; method=:newton), x)[1]\ncatch e\n    e\nend","category":"page"},{"location":"examples/1_basic/#Fixed-point","page":"Basic use cases","title":"Fixed point","text":"","category":"section"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Finally, we show how to differentiate through the limit of a fixed point iteration:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"y longmapsto g(x y)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"The optimality conditions are pretty obvious:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"c(x y) = g(x y) - y = 0","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"To make verification easy, we consider Heron's method:","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"g(x y) = frac12 left(y + fracxyright)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"In this case, the fixed point algorithm boils down to the componentwise square root function, but we implement it manually.","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function forward_fixedpoint(x; iterations)\n    y = ones(eltype(x), size(x))\n    for _ in 1:iterations\n        y .= (y .+ x ./ y) ./ 2\n    end\n    return y\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"function conditions_fixedpoint(x, y; iterations)\n    g = (y .+ x ./ y) ./ 2\n    return g .- y\nend;\nnothing #hide","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"implicit_fixedpoint = ImplicitFunction(forward_fixedpoint, conditions_fixedpoint)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"implicit_fixedpoint(x; iterations=10) .^ 2","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Forward mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> implicit_fixedpoint(_x; iterations=10), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"ForwardDiff.jacobian(_x -> forward_fixedpoint(_x; iterations=10), x)","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Reverse mode autodiff","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"Zygote.jacobian(_x -> implicit_fixedpoint(_x; iterations=10), x)[1]","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"try\n    Zygote.jacobian(_x -> forward_fixedpoint(_x; iterations=10), x)[1]\ncatch e\n    e\nend","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"","category":"page"},{"location":"examples/1_basic/","page":"Basic use cases","title":"Basic use cases","text":"This page was generated using Literate.jl.","category":"page"}]
}
